# ü•ó Tattler Directory ‚Äî Sprint 1: Database Configuration

## üìñ Project Overview
Tattler is a restaurant directory platform designed to offer users a personalized and dynamic experience.  
During **Sprint 1**, the focus was on creating and configuring the **MongoDB database** that will support future API functionality.

---

## ‚öôÔ∏è Objectives
- Configure a **MongoDB** non-relational database to store restaurant and review data in JSON format.
- Import structured data from CSV files.
- Create **indexes** to optimize search and filtering.
- Generate a **backup** using `mongodump` for version control and reproducibility.

---

## üß∞ Tools Used
| Tool | Purpose |
|------|----------|
| **MongoDB Server** | Stores the project‚Äôs data. |
| **MongoDB Compass** | Graphical interface to create collections, import CSVs, and manage indexes. |
| **MongoDB Database Tools** | Provides the `mongodump` and `mongorestore` utilities for database backup and restore. |
| **Node.js / npm** | Used to initialize the Express backend structure for later sprints. |
| **Git & GitHub** | Version control and project delivery. |

---

## üóÇÔ∏è Project Structure

tattler-directory/
‚îÇ
‚îú‚îÄ src/ # Will contain Express app files (Sprint 2)
‚îÇ ‚îú‚îÄ app.js
‚îÇ ‚îú‚îÄ routes/
‚îÇ ‚îú‚îÄ controllers/
‚îÇ ‚îú‚îÄ models/
‚îÇ ‚îî‚îÄ db/
‚îÇ
‚îú‚îÄ data/ # CSV files used to import data into MongoDB
‚îÇ
‚îú‚îÄ backup/ # MongoDB backup generated with mongodump
‚îÇ ‚îî‚îÄ tattler/
‚îÇ ‚îú‚îÄ restaurants.bson
‚îÇ ‚îú‚îÄ restaurants.metadata.json
‚îÇ ‚îú‚îÄ reviews.bson
‚îÇ ‚îî‚îÄ reviews.metadata.json
‚îÇ
‚îú‚îÄ docs/ # Screenshots and evidence of Sprint 1
‚îÇ
‚îú‚îÄ scripts/ # Optional import or seed scripts
‚îÇ
‚îú‚îÄ .env # Environment variables (PORT, MONGODB_URI)
‚îÇ
‚îú‚îÄ package.json
‚îú‚îÄ package-lock.json
‚îî‚îÄ README.md


---

## üçΩÔ∏è MongoDB Database Configuration

### Database: `tattler`
**Collections:**
- `restaurants`
- `reviews`

### Indexes in `restaurants`
| Field | Type | Purpose |
|-------|------|----------|
| `name` | Text | Text search by restaurant name |
| `tags` | Regular | Filter by category/tag |
| `address.city` | Regular | Filter by city |
| `cuisine` | Regular | Filter by cuisine type |
| `avg_rating` | Regular | Sort by rating |
| `price_level` | Regular | Filter by price |

---

## üìä Data Import Process
1. Created CSV files (`restaurants.csv` and `reviews.csv`) inside `/data`.
2. Used **MongoDB Compass ‚Üí Import Data ‚Üí CSV** to populate both collections.
3. Validated that all documents and indexes appear as `READY`.

---

## üíæ Database Backup

To ensure data reproducibility, a complete backup was generated using the **mongodump** tool:

### Command used:
```bash
"C:\Program Files\MongoDB\Tools\100\bin\mongodump.exe" --db=tattler --out="C:\Users\leonm\Documents\TECHNOREADY\CHALLENGE 4\CHALLENGE 4 REP\tattler-directory\backup"

Resulting folder:
	
backup/
 ‚îî‚îÄ tattler/
     ‚îú‚îÄ restaurants.bson
     ‚îú‚îÄ restaurants.metadata.json
     ‚îú‚îÄ reviews.bson
     ‚îî‚îÄ reviews.metadata.json
```
To restore the backup:

mongorestore --db=tattler "backup\tattler"

### üß† Lessons Learned

How to manage a non-relational database in JSON format using MongoDB.

The importance of indexes to optimize search and query performance.

How to use mongodump and mongorestore for versioned backups.

Setting up a clean and scalable folder structure to integrate Express.js in later sprints.




### üß© Versioning

Version 1.0.0 ‚Äî Sprint 1 deliverable


# üçΩÔ∏è Tattler Directory ‚Äî **Sprint 2: API Develop**

## üöÄ Project Goal 
Build a small online service (**API**) that stores restaurant records and lets any website or app **create**, **view**, **update**, **delete**, and **search** them.  
*Analogy:* the API is the **kitchen** that prepares data; apps are the **waiters** that serve it.

---

## üß≠ High-Level Structure
- **Front door (Routes):** Where requests arrive (e.g., ‚Äúshow restaurants in Toluca‚Äù).
- **Clerks (Controllers):** Interpret each request and decide the action.
- **Back room (Database):** Where the records live.
- **Utilities (Config):** Simple settings like DB address and port.
- **Proof (Tests & Screenshots):** Evidence the service works.

> No code reading is needed‚Äîfolders are named by responsibility.

---

## ‚ñ∂Ô∏è How to Run 
1. Install the usual tools: **Node** and **MongoDB**.
2. Add two settings to a `.env` file:
   - `MONGODB_URI` ‚Üí where the database is (local machine).
   - `PORT` ‚Üí which door the service uses (default **3000**).
3. Start the service. A tiny status page confirms it‚Äôs alive:

```txt
GET /health  ‚Üí  { "ok": true, "env": "dev" }
```

## üîå Database Connection ‚Äî *What & Why*

We use **MongoDB**, a flexible, document-style database (each restaurant is one document).  
The app opens **one clean connection** on start. If the DB isn‚Äôt reachable, it **fails fast** with a clear message to avoid silent errors or bad data.

---

## ‚ù§Ô∏è Health Check 

**Visit:**
```http
GET /health
{ "ok": true, "env": "dev" }
```
## üóÇÔ∏è Restaurant Data We Store

- **Name** (e.g., ‚ÄúTattler Burgers‚Äù)
- **Cuisine** (Burgers, Ramen, ‚Ä¶)
- **Address**
  - **Street**
  - **City**
  - **State**
  - **Country**
- **Average rating** (0‚Äì5)
- **Price level** (1‚Äì4)
- **Tags** (e.g., `takeout`, `casual`)

> **Performance note:** We added **indexes** (like a book index) so searches by **city**, **cuisine**, **tags**, **rating**, and **price** remain fast as the dataset grows.

## üîß What the Service Can Do

- **Create** a restaurant (new listing)
- **Read** a restaurant (details)
- **Update** a restaurant (e.g., rating or tags)
- **Delete** a restaurant (remove from directory)
- **Search & filter** (e.g., city + minimum rating)
- **Pagination** (return results in pages for speed)

> **Business value:** The minimal set of capabilities to keep the directory accurate and searchable across channels.

---

## üß™ How We Tested It (Postman)

**Postman** is a point-and-click tool to exercise the API like an app would.  
Our test **collection** (playlist) verifies:

1. **Health** ‚Üí `/health` is alive  
2. **Create** ‚Üí add a restaurant and receive its **ID**  
3. **Read** ‚Üí fetch that restaurant by **ID**  
4. **Update** ‚Üí change the rating and see the update  
5. **List** ‚Üí filter by city + min rating  
6. **Delete** ‚Üí remove it and get a clear confirmation

**Exported collection path:**
```text
tests/TattlerAPI.postman_collection.json
```
Screenshots (green checks) are stored at:
```
tests/screenshots/
```
## üì≤ How Someone Would Use It (Real Life)

- **Discover screen:** ‚ÄúShow restaurants in **Toluca** with **4+ stars**.‚Äù
- **Detail page:** ‚ÄúGive me the info for **restaurant #123**.‚Äù
- **Backoffice edit:** ‚Äú**Update** rating for **#123** to **4.9**.‚Äù
- **Closure:** ‚Äú**Delete #123**,‚Äù and it disappears from search.

---

## ü§ù Access & Collaboration

- Repository is **shared/public**; reviewers added via **GitHub ‚Üí Settings ‚Üí Collaborators**.
- The **Postman collection** and **evidence (screenshots)** live under:
  - `tests/TattlerAPI.postman_collection.json`
  - `tests/screenshots/`

## ‚è±Ô∏è Time Budget (Actual Effort & Cost)

> **Rate:** MXN **$250/hour**

| Activity                                              | Hours | Rate (MXN/h) | Cost (MXN) |
|-------------------------------------------------------|:-----:|:------------:|-----------:|
| Project setup (npm, scripts, .env)                    | 1.0   | 250          | **250**    |
| Mongo connection (`db/mongo.js`)                      | 0.8   | 250          | **200**    |
| Model & indexes (Restaurant)                          | 1.0   | 250          | **250**    |
| Controller & routes (CRUD + filters/pagination)       | 2.5   | 250          | **625**    |
| Postman tests & collection export                     | 1.5   | 250          | **375**    |
| Evidence (screenshots) + export                       | 0.5   | 250          | **125**    |
| README / Sprint 2 documentation                       | 1.2   | 250          | **300**    |
| **Total**                                             | **8.5** | ‚Äî          | **2,125**  |

## üìà Scalability (Grow Without Pain)

- **Data & queries:** Indexes + capped pagination (‚â§ **50**) keep responses quick.
- **Very large datasets:** Consider **MongoDB sharding** (e.g., by `address.city` or `cuisine`).
- **Infrastructure:** Move to **MongoDB Atlas** (replicas, automated backups).
- **Traffic:** Scale the API **horizontally** behind a load balancer (NGINX / cloud).
- **Codebase:** MVC-style structure, middlewares, schema validation (**Zod/Joi**), automated tests (**Jest/Supertest**), and per-environment config.

---

## ‚ôªÔ∏è Sustainability (Maintenance, Cost, Good Practices)

- **Maintainability:** Modular code, thin controllers, centralized error handling; `.env.example` documented; **ESLint + Prettier** for consistency.
- **Cost control:** Local dev or free/shared tiers; scale only when metrics demand it; **TTL/archival** for stale data.
- **Quality & security:** Validate payloads; restrict **CORS** in production; backups if self-hosted; logs/metrics (**Winston / Datadog**) for performance & issues.
- **Delivery impact:** Reusable endpoints across web/mobile; clear docs reduce rework and speed onboarding.

---

## üåø Environmental Sustainability (Greener by Design)

- **Efficient queries = less compute:** Indexes + pagination cut CPU time and energy.
- **Right-sized hosting:** Prefer shared/low-power tiers; scale only with real usage.
- **Auto-sleep for dev/test:** Stop idle services outside work hours.
- **Compact responses:** Return only needed fields and enable **compression** to reduce bandwidth (and carbon).
- **Data lifecycle:** Archive/delete stale records to avoid energy/storage overhead from backups/replication.
- **Tune, don‚Äôt over-provision:** Use observability to optimize instead of adding unnecessary hardware.

---

## üß† Lessons Learned & Pitfalls

- **Postman environments:** Define and select `baseUrl`, or you‚Äôll get **ENOTFOUND**.
- **Desktop Agent for localhost:** Required to reach `http://localhost`.
- **Windows extensions:** Ensure files are real `.js` (not hidden `.js.txt`).
- **Startup clarity:** Fail fast on DB connection issues to avoid ‚Äúhalf-running‚Äù services.

---

## üèÅ Versioning

**Version 2.0.0 ‚Äî Sprint 2 deliverable** *(builds on Sprint 1 database work)*



# üçΩÔ∏è Tattler Directory ‚Äî **Sprint 3: API Develop**

## 1) Project Description

**Tattler Directory** is a REST API for a nationwide restaurant catalog. It lets clients:

- Create / Read / Update / Delete restaurants
- **Search** with free text (`q`) across main fields
- **Filter** by city, cuisine, minimum rating, maximum price, and tags
- **Sort** results (`sortBy`, `order`)
- **Paginate** results with `page` / `limit`
- **Monitor** service health via `GET /health`

This API addresses the challenge of keeping the directory current and relevant so end-users can discover places that match their preferences. It‚Äôs built with **MongoDB** (documents + indexes for fast queries) and **Express.js** (clean routing, MVC-style separation).

## 2) Installation & Usage Instructions

### 2.1 Requirements
- Node.js ‚â• 18  
- MongoDB (Atlas or local)  
- Git

---

### 2.2 Quick Start

```bash
# 1) Clone
git clone <your-repo-url>
cd tattler-directory

# 2) Install deps
npm install

# 3) Environment
cp .env.example .env
# then edit .env with your Mongo URI and PORT

# 4) (Optional) Seed minimal sample data
npm run seed

# 5) Run (dev)
npm run dev
# API running on http://localhost:3000
```
# .env example

```bash
PORT=3000
MONGO_URI=mongodb://localhost:27017/tattler
NODE_ENV=development
CORS_ORIGIN=*
````
### 2.3 Base URL

```bash
http://localhost:3000
`````

In production, replace with your deployed host (e.g., https://api.tattler.mx).

### 2.4 Authentication

Not required for the challenge scope.



#### Health
**GET** `/health`

**200 OK**
```json
{ "status": "ok", "uptime": 123.45, "version": "1.0.0" }
````

#### List restaurants (search, filter, sort, paginate)
**GET** `/api/restaurants`

**Query parameters**

| Param       | Type   | Description                                                                                   |
|-------------|--------|-----------------------------------------------------------------------------------------------|
| `q`         | string | Free-text search in `name`, `cuisine`, `tags`, and `address.city` (case-insensitive).        |
| `city`      | string | Exact city match (case-insensitive).                                                          |
| `cuisine`   | string | Exact cuisine match (case-insensitive).                                                       |
| `minRating` | number | Minimum average rating (`avg_rating >= minRating`).                                           |
| `maxPrice`  | number | Maximum price level (`price_level <= maxPrice`).                                              |
| `tags`      | CSV    | One or multiple tags. Example: `tags=ramen,noodles`.                                          |
| `sortBy`    | enum   | `name` \| `avg_rating` \| `price_level` \| `createdAt` (default: `createdAt`).                |
| `order`     | enum   | `asc` \| `desc` (default: `desc`).                                                             |
| `page`      | number | Page number, 1-based (default: `1`).                                                          |
| `limit`     | number | Page size (default: `10`, max `100`).                                                         |

**Example requests**

```bash
# Free text
curl "http://localhost:3000/api/restaurants?q=ramen"

# City + minimum rating
curl "http://localhost:3000/api/restaurants?city=Toluca&minRating=4"

# Sort by rating (desc)
curl "http://localhost:3000/api/restaurants?sortBy=avg_rating&order=desc"

# Price ceiling + sort by price (asc)
curl "http://localhost:3000/api/restaurants?maxPrice=2&sortBy=price_level&order=asc"

# Pagination
curl "http://localhost:3000/api/restaurants?page=2&limit=10"

# Multi-tag filtering
curl "http://localhost:3000/api/restaurants?tags=ramen,noodles"
````
**Example response**
```json
{
  "meta": {
    "page": 1,
    "limit": 10,
    "total": 37,
    "pages": 4,
    "sortBy": "avg_rating",
    "order": "desc"
  },
  "data": [
    {
      "_id": "68e0...",
      "name": "Ramen Kazu",
      "cuisine": "Japanese",
      "avg_rating": 4.7,
      "price_level": 2,
      "tags": ["ramen", "noodles"],
      "address": { "city": "CDMX", "state": "CDMX", "zip": "06000" },
      "createdAt": "2025-10-01T12:34:56.000Z"
    }
  ]
}
````
Notes

Search uses case-insensitive regex for partial matches.

Filtering and sorting are combined via an aggregation pipeline: $match ‚Üí $sort ‚Üí $facet (with $skip/$limit for pagination).

### CRUD

**Endpoints**

POST /api/restaurants
GET /api/restaurants/:id
PATCH /api/restaurants/:id
DELETE /api/restaurants/:id


**Restaurant schema (simplified)**
```ts
{
  name: string,
  cuisine: string,
  avg_rating: number,     // 0..5
  price_level: number,    // 1..4
  tags: string[],
  address: {
    city: string,
    state?: string,
    zip?: string,
    coords?: { lat: number, lng: number }
  },
  createdAt: ISODate,
  updatedAt: ISODate
}
```
Status codes

200 / 201 ‚Äî success
400 ‚Äî validation error
404 ‚Äî not found
500 ‚Äî server error

### 2.6 Postman / Insomnia Evidence

- **Collection (export v2.1):** `tests/postman/collection_s3.json`
- **Screenshots:**
  - `tests/postman/screens/01_q.png`
  - `tests/postman/screens/02_city_minRating.png`
  - `tests/postman/screens/03_sort_rating_desc.png`
  - `tests/postman/screens/04_sort_price_asc.png`
  - `tests/postman/screens/05_page2_limit10.png`
  - `tests/postman/screens/06_tags_multi.png`

Each screenshot includes the **URL + query params**, **200 OK** status, the **`meta`** object, and the **relevant fields in `data`** for that scenario.

### 2.7 Indexes (Performance)

Created on the collection to support search, filters, and sorting:

- `address.city` (1)
- `cuisine` (1)
- `avg_rating` (-1)
- `price_level` (1)
- `tags` (1)
- `createdAt` (-1)
- `name` (1)

These indexes align with the fields used by `city`, `cuisine`, `minRating`, `maxPrice`, `tags`, and the `sortBy` options to ensure fast lookups and stable sorting.

### 2.8 Troubleshooting

- **500 ‚Äú$elemMatch needs an Object‚Äù**  
  Don‚Äôt use `$elemMatch` with a raw `RegExp` on arrays. Use `tags: /‚Ä¶/i` (regex directly on the array of strings).

- **Empty results**  
  Check your data and query params (note: `city` is exact match, case-insensitive; `q` is partial/regex).

- **Mongo connection issues**  
  Verify `MONGO_URI` in `.env` and confirm MongoDB is reachable.

- **Port conflicts**  
  Change `PORT` in `.env` if `3000` is already in use.

### 2.9 Scripts

**package.json**
```json
{
  "scripts": {
    "dev": "nodemon src/app.js",
    "start": "node src/app.js",
    "seed": "node scripts/seed.js"
  }
}
```

## 3) Repository Structure

```
tattler-directory/
‚îú‚îÄ src/
‚îÇ  ‚îú‚îÄ app.js                 # Express app bootstrap (routes, middlewares, CORS)
‚îÇ  ‚îú‚îÄ routes/
‚îÇ  ‚îÇ  ‚îî‚îÄ restaurants.js      # GET with search/filter/sort/pagination + CRUD
‚îÇ  ‚îú‚îÄ models/
‚îÇ  ‚îÇ  ‚îî‚îÄ Restaurant.js       # Mongoose schema + indexes
‚îÇ  ‚îú‚îÄ db/
‚îÇ  ‚îÇ  ‚îî‚îÄ mongo.js            # Mongoose connect (loaded at startup)
‚îÇ  ‚îú‚îÄ middlewares/
‚îÇ  ‚îÇ  ‚îî‚îÄ error.js            # Centralized error handling (optional)
‚îÇ  ‚îî‚îÄ utils/
‚îÇ     ‚îî‚îÄ validate.js         # Param parsing/validation (optional)
‚îú‚îÄ scripts/
‚îÇ  ‚îî‚îÄ seed.js                # Sample data loader (optional)
‚îú‚îÄ tests/
‚îÇ  ‚îî‚îÄ postman/
‚îÇ     ‚îú‚îÄ collection_s3.json
‚îÇ     ‚îî‚îÄ screens/            # 01_q.png ... 06_tags_multi.png
‚îú‚îÄ .env.example
‚îú‚îÄ README.md
‚îú‚îÄ package.json
‚îî‚îÄ LICENSE
```

### Database Desktop Tool (evidence)

I used **MongoDB Compass** to connect to the project database, browse collections, and validate queries during development. In Compass I verified the connection (using my `.env` connection string), inspected documents to confirm schema consistency (`name`, `cuisine`, `avg_rating`, `price_level`, `tags`, `address.city`), and executed ad-hoc queries (by `city`, `cuisine`, and rating ranges) to cross-check the same filters exposed by the API. I also reviewed the **Indexes** tab to confirm that the indexes defined in the model (`address.city`, `cuisine`, `avg_rating`, `price_level`, `tags`, `createdAt`, `name`) were created and aligned with the search/sort patterns. For the purposes of this challenge, Compass serves as a **drop-in alternative to Studio 3T**: it provides equivalent capabilities for connection, data exploration, query testing, and index inspection‚Äîtherefore it fully satisfies the desktop-tool requirement.

**Evidence (screenshots in `tests/compass/`):**
- `01_connect.png` ‚Äî successful connection to the database  
- `02_browse_collection.png` ‚Äî collection view showing example documents and fields  
- `03_query_city_rating.png` ‚Äî query by `address.city` and `avg_rating` demonstrating expected matches  
- `04_indexes.png` ‚Äî index list confirming the fields used for filtering and sorting

## ‚è±Ô∏è Time Budget (Updated with Sprint 3)

### Sprint 3 only
| Activity                                                     | Hours | Rate (MXN/h) |   Cost (MXN) |
|--------------------------------------------------------------|:-----:|:------------:|-------------:|
| Branch setup + checklist (`s3-search-sort`)                  |  0.3  |     250      |         75   |
| Model refresh & new indexes (`name`, `createdAt`, etc.)      |  0.7  |     250      |        175   |
| Search/Filter/Sort endpoint (Aggregation Pipeline)           |  2.0  |     250      |        500   |
| Query param parsing & error handling (validation basics)     |  0.5  |     250      |        125   |
| Postman tests (6‚Äì8 reqs) + collection export                 |  1.0  |     250      |        250   |
| Evidence screenshots (responses & meta)                      |  0.5  |     250      |        125   |
| README ‚ÄúSearch & Sort v2‚Äù (usage examples & params)          |  0.8  |     250      |        200   |
| MongoDB Compass evidence + README note (alt. to Studio 3T)   |  0.4  |     250      |        100   |
| Pull Request + add collaborators                              |  0.3  |     250      |         75   |
| **Total Sprint 3**                                           | **6.5** |      ‚Äî       |   **1,625**  |

### Cumulative (Sprint 2 + Sprint 3)
| Period    | Hours | Cost (MXN) |
|-----------|:-----:|-----------:|
| Sprint 2  |  8.5  |     2,125  |
| Sprint 3  |  6.5  |     1,625  |
| **Total** | **15.0** | **3,750** |

## üìà Scalability (Grow Without Pain) ‚Äî Updated

- **Queries & Data:** Use compound indexes for frequent filters/sorts (`address.city`, `cuisine`, `avg_rating`, `price_level`, `tags`, `createdAt`, `name`). Keep pagination **capped (‚â§ 100)** to protect memory/CPU.
- **Search:** For richer text search at scale, consider a **text index** or **Atlas Search** (analyzers, scoring) instead of regex.
- **Sorting at scale:** Ensure sort fields are indexed; when sorting by low-selectivity fields, add a tiebreaker (e.g., `_id`) for stable cursors.
- **Pagination:** Consider **cursor-based** pagination for deep scrolling; current `$skip/$limit` is fine for moderate pages.
- **Traffic:** Add **rate limiting** + **request timeouts**; cache hot queries (in-memory/Redis) with short TTLs.
- **API Contract:** Publish **OpenAPI/Swagger**; version endpoints (`/v1`) to evolve safely.
- **Infra:** Prefer **MongoDB Atlas** (replicas, backups); scale the API horizontally behind a load balancer.

---

## ‚ôªÔ∏è Sustainability (Maintenance, Cost, Good Practices) ‚Äî Updated

- **Maintainability:** MVC routing, thin controllers, shared utils for param parsing; centralized error handler; keep `.env.example` in repo.
- **Quality & Security:** Add schema validation (**Zod/Joi**) and tests (**Jest/Supertest**); restrict **CORS** in prod; logging with **Winston**; basic write audit logs.
- **Cost control:** Start on free/local tiers and scale based on metrics. Archive stale records; return only needed fields via `$project`.
- **DX & Ops:** **Prettier/ESLint**, Husky pre-commit hooks, and a lightweight CI (lint + test) to prevent regressions.



## üèÅ Versioning

**Version 3.0.0 ‚Äî Sprint 2 deliverable** *(builds on Sprint 1 database work)*

